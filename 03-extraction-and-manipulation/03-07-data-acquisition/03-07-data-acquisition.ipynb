{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition\n",
    "\n",
    "Modern Data sources typically deliver their data over an API. In this exercise, we will first acquire some tweets and work with them in various ways.\n",
    "\n",
    "We'll be working with [`tweepy`](https://github.com/tweepy/tweepy), an API for acquiring Data from Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best place to start is the [documentation](http://docs.tweepy.org/en/latest/). Take a look at the Getting Started page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, install `tweepy` using pip. You need only do it once (but doing it more than once won't hurt anything). To install it, run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  <span style=\"font-size:16px;font-weight:normal;\">The next step is to obtain Twitter credentials for being able to acccess the API.<br /><br />Visit the [Twitter Developer Site](https://developer.twitter.com/) to create a twitter \"application.\" <br /><br /> Go to the keys and tokens tab (shown alongside) and copy-paste the Consumer API keys as well as the Access token & access token secret into the cell below. <br /><br />Careful! `consumer_secret` and `access_token_secret` should be protected like passwords because they can be used by the API to <em>send out tweets or direct messages</em> on your behalf (this is what Twitter bots do!). Invalidate the token info after submitting your notebook (by regenerating a new set of token values on the keys and tokens page).</span> | ![alt text](TwitterDev.png \"Title\") |\n",
    "|:--- | --- |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = '▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣'\n",
    "consumer_secret = '▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣'\n",
    "access_token = '▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣'\n",
    "access_token_secret = '▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "API = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tweets = API.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Did you get some tweets?\n",
    "\n",
    "Good! The API documentation is [here](http://docs.tweepy.org/en/latest/api.html).\n",
    "We will use the API for finding information about your favorite Twitter user: things like their latest tweets, their followers, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First enter the name of a prominent user, say @nytimes.\n",
    "user = '@nytimes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets from your prominent user\n",
    "user_tweets = API.user_timeline(user)\n",
    "for tweet in user_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each user_tweet is actually an object! Use dir(...) to find its attributes\n",
    "# dir(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some followers of your favorite user\n",
    "user_friends = API.friends(user)\n",
    "for friend in user_friends:\n",
    "    print(friend.screen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO-DO\n",
    "\n",
    "1. Have the students exercise some functions of the API and the data it returns.\n",
    "1. Create a DataFrame with attributes of a user: (id, name, recent_tweets). Note that `id` and `name` will be a string whereas `recent_tweets` will be a list of strings.\n",
    "1. Iterate through the top 20 `friends` and add _their_ data into the above DataFrame. Now you will have 21 rows in the DataFrame.\n",
    "1. Iterate through the top 5 `friends` of each `friend` but don't allow duplicates in the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More TO-DO\n",
    "\n",
    "1. Add a new column `sentiment` to the above DataFrame.\n",
    "1. Download [AFINN Data](https://github.com/fnielsen/afinn/blob/master/afinn/data/AFINN-en-165.txt) and convert it to a Python Dictionary `sentiment_dict`.\n",
    "1. Accumulate the sentiment score for each word in the tweet text; if a word is not in `sentiment_dict` its weight should be considered zero.\n",
    "1. Who (in your DataFrame) has the highest sentiment score and who has the least?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Even more TO-DO\n",
    "\n",
    "1. Add new columns `recent_hashtags` and `recent_mentions` to the DataFrame. Some of these attributes are not directly available in the API. You will have to examine the text for words that start with '#' and '@' respectively. The `recent_hashtags` and `recent_mentions` attributes for each user should be a dictionary of words and counts. For example, with `user = '@nytimes'` last weekend `#syria` might have been a popular recent hashtag.\n",
    "1. What was the most popular hashtag?\n",
    "1. Who was the most frequent mention in your DataFrame?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
